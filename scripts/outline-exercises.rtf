{\rtf1\ansi\ansicpg1252\cocoartf1138\cocoasubrtf510
{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh14460\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\f0\fs24 \cf0 \
Exercises:\
\
Using raw nifti data, write a split-half correlation analysis using data from different ROIs.\
Compare the 'ev', 'vt' and 'brain' ROI results. \
What happens if you use betas instead of t values?\
\
Generate synthetic data using cosmo_generate_synthetic data. vary the class_distance parameter and make scatter plots of pairs of the first few dimensions using the standard settings. \
* Add code to support different_on_all_dimensions=True \
\
Consider the naive basin classifier. Generate a set of synthetic data and train and test on the same data; compute classification accuracy. Also split the synthetic data in half (see cosmo_dataset_select_samples and use ds.sa.chunks).\
\
Implement a nearest neighbor classifier. Do the same classification as with the naive baysian classifier. What happens to the classification accuracy? Why?\
\
* Complete a wrapper function for svmtrain and svmclassify that can do two-class classification. Test on the synthetic data.\
\
* Write a meta multi class classifier that uses another (possibly two-class) classifier to do all pair-wise (across classes) classifications and uses majority voting. Test on the synthetic data.\
\
** Implement a meta classifier that takes multiple classifiers as input and uses majority voting across the different classifiers\
\
Complete the 
\fs20 cosmo_nfold_partition
\fs24  and 
\fs20 cosmo_cross_validate
\fs24  functions, and run cross-validation on the synthetic data using the naive baysian and nearest neighbor classification.\
\
Using the provided function fmri_dataset, load the t-values from all ten runs of subject s01 with the brain mask (the 'canonical dataset'), set chunks and targets properly, and run cross validation on the 'ev' and 'vt ROIs using your favorite classifier.\
\
Complete the sphere_offsets functions, then complete the searchlight example code.\
\
The 
\fs20 spherical_voxel_selection
\fs24  function has been provided; try it out on the canonical dataset. Plot a histogram of the number of selected voxels across features.\
** Add functionality to this function to return a fixed number of voxels in each searchlight (using variably sphere radii).\
\
Complete the searchlight example that uses spherical_voxel_selection, using nfold partitioning and the nearest neighbor classifier. Look at the output map. \
* Re-run with betas rather than t-values and compare the maps\
\
Complete the randomize_targets, then do cross validation  accuracies using the nearest neighbor classifier and a dataset 
\fs20 ds=cosmo_generate_synthetic_dataset(1)
\fs24 . Then 
\fs20 do a thousand iterations where the labels are permuted compared to the original dataset to get null distribution accuracies. Compute the p-value by considering the original accuracy and the accuracies of the null distributions. Plot the histogram of null accuracies. Re-run multiple times; how much does the p-value vary? What happens if you use 100 or 5,000 iterations instead?\
\
\
TODO:\
RSA/dimensionality reduction/template matching searchlight\
feature selection\

\fs24 \
\
\
\
\
\
\
\
\
\
\
}